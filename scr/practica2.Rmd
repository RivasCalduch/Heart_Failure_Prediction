---
title: "Practica 2: Data Cleaning "
author: "Jose Luis Rivas Calduch  y Mariano Jiménez Barca"
date: "11 de diciembre de 2020"
output: pdf_document
toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, include=FALSE}

# Cargamos la libreria que vamos a emplear para cargar el fichero csv
library(readr)

# Cargamos el data set
rawData <- read.csv("../data/heart_failure_clinical_records_dataset.csv")

#Cargamos las librerías que vamos a utilizar



```

## 1. Descripción del dataset.

El data set objeto de estudio esta tomado de la plataforma *Kaggle*. Esta es una comunidad en línea de científicos de datos y profesionales del aprendizaje automático, actualmente es una subsidiaria de *Google LLC*.

El nombre del data set es *Heart Failure Prediction* (ECV) que son la principal causa de muerte a nivel mundial, cobrando un estimado de 17,9 millones de vidas cada año, lo que representa el 31% de todas las muertes en todo el mundo.
La insuficiencia cardíaca es un evento común causado por las enfermedades cardiovasculares y este conjunto de datos contiene 12 características que se pueden usar para predecir la mortalidad por insuficiencia cardíaca.

La mayoría de las enfermedades cardiovasculares se pueden prevenir abordando los factores de riesgo conductuales como el consumo de tabaco, la dieta poco saludable y la obesidad, la inactividad física y el consumo nocivo de alcohol utilizando estrategias para toda la población.

Las personas con enfermedad cardiovascular o que se encuentran en alto riesgo cardiovascular (debido a la presencia de uno o más factores de riesgo como hipertensión, diabetes, hiperlipidemia o enfermedad ya establecida) necesitan una detección y manejo precoces donde un modelo de aprendizaje automático puede ser de gran ayuda.

**Tipos de variables**

```{r}

sapply(rawData, class)

```

**Descripción de las variables**

```{r}

str(rawData)

```

**Resumen descriptivo de las variables**

```{r}

summary(rawData)

```

## 2. Integración y selección de los datos de interés a analizar.

## 3. Limpieza de los datos.

## 4. Análisis de los datos

### 4.1. Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).

### 4.2. Comprobación de la normalidad y homogeneidad de la varianza.

### 4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos. 

## 5. Representación de los resultados a partir de tablas y gráficas.

## 6. Resolución del problema.

## Bilbliografia

*Subirats Maté, Laila; Pérez Trenard, Diego O.; Calvo González, Mireia (2019)* Introducción al ciclo de la vida de los datos. UOC
*Subirats Maté, Laila; Calvo González, Mireia (2019)* Web scraping. UOC
*Subirats Maté, Laila; Pérez Trenard, Diego O.; Calvo González, Mireia (2019)* Introducción a limpieza y análisis de los datos. UOC
*Hernández Orallo, José; Ramirez Quintana, M José; Ferri Ramírez, Cesar (2004)* Introducción a la Minería de Datos. PEARSON.
*Gironés Roig, Jordi; Casas Roma, Jordi; Minguillon Alfonso, Julia; Caichuelas Quiles, Ramon (2017)* Minería de datos: Modelos y algoritmos. UOC.

## Agradecimientos

*Cita*
Davide Chicco, Giuseppe Jurman: Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. BMC Medical Informatics and Decision Making 20, 16 (2020). (link)

*License*
CC BY 4.0
